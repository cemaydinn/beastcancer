{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1gZR3QQqE6FQpRJnGP_8cqEiRz14iqhrf","timestamp":1716632252126},{"file_id":"1kpMZ6E0HhOmTCSRgzLdlow0x5aewHr7D","timestamp":1715094018240}],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Checking The Overfitting\n","\n","- Breast Cancer Classification modeli adı verilen bir model geliştirilmiştir. İlgili mühendis bu modelin accuracy değerinin yüzde 98 olduğunu iddia etmektedir. Ancak modelin hastalarımız ile ilgili yaptığı yanlış tahminler hastanemizi sıkıntıya sokmaktadır :)\n","\n","- Bu modeli tekrar geliştiriniz ve sonuçları yorumlayınız.\n","\n","Logistic regression bölümünde elde ettiğimiz model accuracy değeri yüzde 98 idi. Bu durum bize aşırı öğrenme problemine düşebileceğimizi düşündürmüştü. Mühendisimizin günahını da alıyor olabiliriz. Bilmiyoruz.\n","\n","Bu sebeple aşırı öğrenme önlemleri alarak yeni bir model geliştirmemiz gerekiyor.\n","\n","Bu veri setini tekrar modelleyiniz.\n","\n","Dikkat edilmesi gerekenler:\n","\n","- sklearn içerisinde yer alan breast cancer veri setini kullanınız. (from sklearn.datasets import load_breast_cancer)\n","\n","- Veri ön işleme adımında amelasyon yapılabilir. Fonksiyon yazılmasına gerek yok.\n","\n","- Tensorflow dataset için tanımladığımız fonksiyonu kullanınız ve batch_size'ı 32 yapınız.\n","\n","- 1 gizli katmanlı basit bir model oluşturunuz. Nöron sayısını istediğiniz gibi tercih edebilirsiniz.\n","\n","- Aşırı öğrenme problemine karşı uygun katman yapılarını ve callback'i kullanınız.\n","\n","- Model compile bölümünde SGD'yi direkt kullanınız yani compile içinde optimizer=\"SGD\" şeklinde kullanınız.\n","\n","- Overfitting'den şüphelendiğimiz için early stopping'de küçük bir değer giriniz.\n","\n","- En iyi epoch sonucunu yorumlayınız.\n","\n","- Loss eğrisini yorumlayınız.\n","\n","- İfade edilmeyen konularda tercih size bırakılmıştır.\n","\n","- Notebook'ta genel yapılar ve gidiş yolu için yönlendirmeler bırakılmıştır.\n"],"metadata":{"id":"j3SgiO7Ekx1k"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jZf6nNNim8uI","outputId":"af15fbd9-c5bd-404a-e56a-60b65c4ebc68","executionInfo":{"status":"ok","timestamp":1716637797250,"user_tz":-120,"elapsed":390,"user":{"displayName":"Vahit Keskin","userId":"01629533593928328348"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Keras Current Version: 3.3.3 Tensorflow Current Version: 2.16.1\n"]}],"source":["import keras\n","import tensorflow as tf\n","print(\"Keras Current Version:\", keras.__version__, \"Tensorflow Current Version:\", tf.__version__)"]},{"cell_type":"code","source":["# !pip uninstall tf-keras"],"metadata":{"id":"Abs552b_KvBw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install tensorflow==2.16.1"],"metadata":{"id":"sU4XoHN5Kw1K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Imports and Settings"],"metadata":{"id":"CALKB2x9EpFi"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import random\n","import matplotlib.pyplot as plt\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import load_breast_cancer\n","\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n","\n","random.seed(46)\n","np.random.seed(46)\n","tf.random.set_seed(46)\n"],"metadata":{"id":"0t4vFeI2EoP2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Functions"],"metadata":{"id":"pPMM45jJgkAA"}},{"cell_type":"code","source":["def plot_training_history(history, train_loss='loss', train_metric='accuracy', val_loss='val_loss', val_metric='val_accuracy'):\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(history.history[train_loss], label='Training Loss')\n","    plt.plot(history.history[val_loss], label='Validation Loss')\n","    plt.title('Training and Validation Loss Over Epochs')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(history.history[train_metric], label=f\"Training: {train_metric}\")\n","    plt.plot(history.history[val_metric], label=f\"Validation: {val_metric}\")\n","    plt.title(f'Training and Validation {train_metric} Over Epochs')\n","    plt.xlabel('Epochs')\n","    plt.ylabel(f'train_metric')\n","    plt.legend()\n","    plt.show()\n","\n","\n","def get_best_epoch_details(history):\n","    val_losses = history.history['val_loss']\n","    min_val_loss_index = val_losses.index(min(val_losses))\n","    best_epoch = min_val_loss_index + 1\n","\n","    epoch_details = {}\n","    for key in history.history.keys():\n","        epoch_details[key] = history.history[key][min_val_loss_index]\n","\n","    epoch_details['best_epoch'] = best_epoch\n","    return epoch_details\n","\n","def prepare_datasets(X_train, X_val, y_train, y_val, batch_size=None):\n","\n","    if batch_size is None:\n","        batch_size = len(X_train)\n","\n","    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n","    train_dataset = train_dataset.shuffle(buffer_size=len(X_train)).batch(batch_size)\n","    val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n","    val_dataset = val_dataset.batch(batch_size)\n","\n","    return train_dataset, val_dataset\n"],"metadata":{"id":"lHPye0XJcX2o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Preprocess, Train Validation and Tensorflow Dataset"],"metadata":{"id":"nAm1gASwgpOz"}},{"cell_type":"markdown","source":["# Task 1: Veri setini yükleyiniz ve X ve y'yi alınız."],"metadata":{"id":"xHD-fq5pBK6K"}},{"cell_type":"code","source":[],"metadata":{"id":"7oX2IckhBSDe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Task 2: Train Validasyon seti ayrımını yapınız"],"metadata":{"id":"Qvp-7YeMBVSk"}},{"cell_type":"code","source":[],"metadata":{"id":"hFOQQzmnBbPC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Task 3: X_train ve X_val setlerini standart scaler'dan geçiriniz"],"metadata":{"id":"gPUsaeqFBbvw"}},{"cell_type":"code","source":[],"metadata":{"id":"ba5Oy5XVBTx8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Task 4: Tensorflow Dataset oluşturunuz"],"metadata":{"id":"43S-vtKlBkRI"}},{"cell_type":"code","source":[],"metadata":{"id":"Q2shXRjXFiPi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"om5kthg0FiPi"}},{"cell_type":"markdown","source":["# Task 5: Model yapısını aşırı öğrenme için uygun katmanları da kullanarak oluşturunuz"],"metadata":{"id":"ZauxAuMxB7jo"}},{"cell_type":"code","source":[],"metadata":{"id":"bF4Vr8b2FiPi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Task 6: Modeli SGD ile, binary_crossentropy ve accuracy, AUC değerleri ile compile ediniz."],"metadata":{"id":"FXqxKf6dCAuY"}},{"cell_type":"code","source":[],"metadata":{"id":"zT1lJnaOCBUf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Task 7: Early stopping callback'i tanımlayınız."],"metadata":{"id":"U2HsSrRaCP1Y"}},{"cell_type":"code","source":[],"metadata":{"id":"qETRH39VCP9B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Task 8: Modeli train ediniz"],"metadata":{"id":"fIeObonZCV6C"}},{"cell_type":"code","source":[],"metadata":{"id":"wBSfz7EuCWDg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Task 9: En iyi epoch değerlerini getiriniz ve yorumlayınız."],"metadata":{"id":"Ie9LsCXGCZ6O"}},{"cell_type":"code","source":[],"metadata":{"id":"PfhuTdTlCaBV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mLAFKgjTEFMt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Task 10: Train history'sini görselleştiriniz ve yorumlayınız"],"metadata":{"id":"iUPnDKAOCaHT"}},{"cell_type":"code","source":[],"metadata":{"id":"ekmoVkVtCaNr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tbr-47rQEg3j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Task 11: Modelin aşırı öğrenme durumu ile ilgili ne düşünüyorsunuz?"],"metadata":{"id":"e_hym-J6Ctpv"}},{"cell_type":"code","source":[],"metadata":{"id":"ujLhoPvCC0cR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rqfHNELxMJdK"},"execution_count":null,"outputs":[]}]}